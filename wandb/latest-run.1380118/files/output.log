Time to play:
Loading lists of data
graph data Data(x=[81, 1], edge_index=[2, 324], y=[81], pos=[81, 2])
Epoch: 10  Train Loss: 83918.4801947023  Validation Loss: 82174.42023519489
Epoch: 20  Train Loss: 82896.49208892154  Validation Loss: 79353.54550039429
Epoch: 30  Train Loss: 80584.69024440042  Validation Loss: 74704.20905036504
Epoch: 40  Train Loss: 76341.75717418181  Validation Loss: 68995.7751309991
Epoch: 50  Train Loss: 70017.0078638066  Validation Loss: 59535.7349561685
Epoch: 60  Train Loss: 61192.00137136999  Validation Loss: 51239.26980767006
Epoch: 70  Train Loss: 50889.743774523005  Validation Loss: 44437.097726404565
Epoch: 80  Train Loss: 40928.79551885891  Validation Loss: 43803.42059258182
Epoch: 90  Train Loss: 32254.659362434337  Validation Loss: 45171.9533341433
Epoch: 100  Train Loss: 23887.70421871298  Validation Loss: 45029.085639307894
Epoch: 110  Train Loss: 18570.644482323663  Validation Loss: 45189.35996670643
Epoch: 120  Train Loss: 10562.608871267546  Validation Loss: 36074.957688319846
Epoch: 130  Train Loss: 5647.2967242906625  Validation Loss: 33112.81842433283
Epoch: 140  Train Loss: 3929.3623110477206  Validation Loss: 22171.210585687837
Epoch: 150  Train Loss: 2860.391462387501  Validation Loss: 19817.23577473762
Epoch: 160  Train Loss: 3266.2188992307106  Validation Loss: 18199.73351395987
Epoch: 170  Train Loss: 1940.9003535874915  Validation Loss: 11057.400153840394
Epoch: 180  Train Loss: 1670.8294648452845  Validation Loss: 13591.284986182678
Epoch: 190  Train Loss: 1893.3083931462  Validation Loss: 8165.499826237237
Epoch: 200  Train Loss: 8721.46368762976  Validation Loss: 26351.988927272192
Epoch: 210  Train Loss: 4466.372718681031  Validation Loss: 14825.853546899216
Epoch: 220  Train Loss: 1834.3279751466287  Validation Loss: 9310.340441960307
Epoch: 230  Train Loss: 1462.5442422041895  Validation Loss: 5860.4684695315245
Epoch: 240  Train Loss: 1827.5168831785402  Validation Loss: 6481.452021839995
Epoch: 250  Train Loss: 1203.4657439890898  Validation Loss: 5435.459147190908
Epoch: 260  Train Loss: 1111.0733946658406  Validation Loss: 4549.650228820103
Epoch: 270  Train Loss: 1340.94496195796  Validation Loss: 4876.963909906224
Epoch: 280  Train Loss: 1152.6627563930033  Validation Loss: 4070.642908726864
Epoch: 290  Train Loss: 1817.0407559609541  Validation Loss: 3963.4998336904073
Epoch: 300  Train Loss: 1258.1768522191169  Validation Loss: 4392.420004894927
Epoch: 310  Train Loss: 1406.0318607585984  Validation Loss: 3318.817592390771
Epoch: 320  Train Loss: 932.9585592240472  Validation Loss: 2810.2286790901003
Epoch: 330  Train Loss: 1522.4450261420536  Validation Loss: 3961.5034612948566
Epoch: 340  Train Loss: 905.0372342193936  Validation Loss: 3354.871317933313
Epoch: 350  Train Loss: 839.8912973718403  Validation Loss: 3911.663441911224
Epoch: 360  Train Loss: 1538.8469180123686  Validation Loss: 5210.949224229005
Epoch: 370  Train Loss: 1499.7083618839004  Validation Loss: 4363.895520796609
Epoch: 380  Train Loss: 924.4004070217312  Validation Loss: 2654.5766346870564
Epoch: 390  Train Loss: 906.7151222829356  Validation Loss: 2996.1692858346487
Epoch: 400  Train Loss: 1028.474735563573  Validation Loss: 3864.662807469038
Epoch: 410  Train Loss: 965.9780176638583  Validation Loss: 3293.1454992728286
Epoch: 420  Train Loss: 947.4614114148934  Validation Loss: 4640.192142912964
Epoch: 430  Train Loss: 868.4925500863642  Validation Loss: 3485.4066680518677
Epoch: 440  Train Loss: 742.1852186550428  Validation Loss: 3057.8856056125187
Epoch: 450  Train Loss: 808.5994948032823  Validation Loss: 2725.519251575548
Epoch: 460  Train Loss: 1071.883243250885  Validation Loss: 3452.2412778594585
Epoch: 470  Train Loss: 1034.5477826366362  Validation Loss: 4463.030209089147
Epoch: 480  Train Loss: 938.2314960301547  Validation Loss: 2521.858635389536
Epoch: 490  Train Loss: 912.2161611804077  Validation Loss: 3996.3104210215315
Epoch: 500  Train Loss: 988.5045146130727  Validation Loss: 2718.4901412979543
Epoch: 510  Train Loss: 750.9861309693506  Validation Loss: 3193.3917790053574
Epoch: 520  Train Loss: 889.0027922823123  Validation Loss: 4585.026672774721
Epoch: 530  Train Loss: 653.9170426454248  Validation Loss: 2160.423242450802
Epoch: 540  Train Loss: 876.5694804650512  Validation Loss: 2171.336429954666
Epoch: 550  Train Loss: 841.879466692821  Validation Loss: 2256.5170254204377
Epoch: 560  Train Loss: 728.2568042802191  Validation Loss: 2288.7627137590885
Epoch: 570  Train Loss: 823.1511477228514  Validation Loss: 4000.908040510426
Epoch: 580  Train Loss: 707.8583654879009  Validation Loss: 2620.605514745611
Epoch: 590  Train Loss: 856.9778226654186  Validation Loss: 3236.053820054962
Epoch: 600  Train Loss: 1121.1604793616293  Validation Loss: 4067.345600926632
Epoch: 610  Train Loss: 623.8017365516923  Validation Loss: 2610.352613073106
Epoch: 620  Train Loss: 957.5197200216486  Validation Loss: 2118.522458654298
Epoch: 630  Train Loss: 602.9817185036355  Validation Loss: 2048.239970696706
Epoch: 640  Train Loss: 812.6810742875001  Validation Loss: 3362.711360614518
Epoch: 650  Train Loss: 664.5660611197062  Validation Loss: 2462.9102747353454
Epoch: 660  Train Loss: 698.6023482784334  Validation Loss: 2256.872018740283
Epoch: 670  Train Loss: 553.2551591325408  Validation Loss: 2481.6894312926493
Epoch: 680  Train Loss: 689.850455642238  Validation Loss: 2130.5109051099043
Epoch: 690  Train Loss: 783.9203813613773  Validation Loss: 3395.1967274586195
Epoch: 700  Train Loss: 704.2091325552962  Validation Loss: 2405.085847876153
Epoch: 710  Train Loss: 971.6839349479942  Validation Loss: 2051.22064529637
Epoch: 720  Train Loss: 639.7469726394344  Validation Loss: 2155.914765968032
Epoch: 730  Train Loss: 602.4903072041411  Validation Loss: 2067.0318142509814
Epoch: 740  Train Loss: 734.1419992830565  Validation Loss: 2028.6554431845643
Epoch: 750  Train Loss: 755.5367589971789  Validation Loss: 2296.260818459112
Epoch: 760  Train Loss: 597.6509893090014  Validation Loss: 1721.1058483109414
Epoch: 770  Train Loss: 848.8623004036903  Validation Loss: 2036.8377408737872
Epoch: 780  Train Loss: 632.7227685416769  Validation Loss: 1850.6288895830808
Epoch: 790  Train Loss: 545.5302015666475  Validation Loss: 2146.2010896049956
Epoch: 800  Train Loss: 600.2110617629996  Validation Loss: 1767.5120486423684
Epoch: 810  Train Loss: 630.0788249126396  Validation Loss: 2468.3744706056045
Epoch: 820  Train Loss: 640.7992742845995  Validation Loss: 1732.893331225731
Epoch: 830  Train Loss: 532.4719974230067  Validation Loss: 1855.1548276219223
Epoch: 840  Train Loss: 622.9043769558634  Validation Loss: 2198.9303500070873
Epoch: 850  Train Loss: 485.4872716958427  Validation Loss: 2734.7775455232145
Epoch: 860  Train Loss: 1002.9757047811969  Validation Loss: 2055.200907844975
Epoch: 870  Train Loss: 520.1493160244685  Validation Loss: 1846.684662874744
Epoch: 880  Train Loss: 618.5731412430886  Validation Loss: 1755.2882159199055
Epoch: 890  Train Loss: 548.0765940595497  Validation Loss: 1503.8829061598717
Epoch: 900  Train Loss: 649.7061140002035  Validation Loss: 1972.4457583764702
Epoch: 910  Train Loss: 647.9076238028061  Validation Loss: 1979.6066913595257
Epoch: 920  Train Loss: 445.93143387286955  Validation Loss: 1393.5852647973995
Epoch: 930  Train Loss: 800.0881302689723  Validation Loss: 2725.542877968696
Epoch: 940  Train Loss: 511.60915017800716  Validation Loss: 1696.4589777888398
Epoch: 950  Train Loss: 480.43476850440146  Validation Loss: 1531.0651173690592
Epoch: 960  Train Loss: 452.35519163762297  Validation Loss: 1723.6835254043742
Epoch: 970  Train Loss: 518.0444149885229  Validation Loss: 1689.2538405512425
Epoch: 980  Train Loss: 418.0113037624232  Validation Loss: 1410.999412358543
Epoch: 990  Train Loss: 671.3037654887506  Validation Loss: 1893.1405099629737
torch.Size([8100])
torch.Size([8100])
100
100
Average Test Loss (MSE) tensor(1296.5444, device='cuda:0', grad_fn=<DivBackward0>)