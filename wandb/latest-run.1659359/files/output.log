Time to play:
Loading lists of data
graph data Data(x=[81, 1], edge_index=[2, 324], y=[81], pos=[81, 2])
Epoch: 10  Train Loss: 83626.82612725504  Validation Loss: 81749.72246925045
Epoch: 20  Train Loss: 82203.67149178057  Validation Loss: 78578.19638829406
Epoch: 30  Train Loss: 79429.34810163868  Validation Loss: 74265.56448296175
Epoch: 40  Train Loss: 74562.93334450039  Validation Loss: 66676.3202821873
Epoch: 50  Train Loss: 67251.21940801087  Validation Loss: 57620.774131302845
Epoch: 60  Train Loss: 57874.79035936948  Validation Loss: 48468.9759381781
Epoch: 70  Train Loss: 47222.92290158882  Validation Loss: 44394.330992389456
Epoch: 80  Train Loss: 35925.23750129558  Validation Loss: 44618.2687469061
Epoch: 90  Train Loss: 24639.512917420143  Validation Loss: 47020.18124699227
Epoch: 100  Train Loss: 15184.583747454628  Validation Loss: 45924.57069865576
Epoch: 110  Train Loss: 8111.403175022841  Validation Loss: 40850.87415155529
Epoch: 120  Train Loss: 4264.644099771388  Validation Loss: 41097.89248331435
Epoch: 130  Train Loss: 2806.4811288369533  Validation Loss: 29284.068204852665
Epoch: 140  Train Loss: 2326.2383944027183  Validation Loss: 17893.434392560765
Epoch: 150  Train Loss: 2734.7567354250928  Validation Loss: 14284.9915244854
Epoch: 160  Train Loss: 2657.7628709600594  Validation Loss: 14709.523932961762
Epoch: 170  Train Loss: 1791.8554728287306  Validation Loss: 10855.890959718503
Epoch: 180  Train Loss: 2213.8998420834873  Validation Loss: 12628.82795620777
Epoch: 190  Train Loss: 1485.4272551340885  Validation Loss: 9538.244385794242
Epoch: 200  Train Loss: 1423.6501576515939  Validation Loss: 9128.299596814706
Epoch: 210  Train Loss: 1520.2286465284706  Validation Loss: 11974.212290030395
Epoch: 220  Train Loss: 1324.180776015147  Validation Loss: 8505.25806021598
Epoch: 230  Train Loss: 1440.2273321824923  Validation Loss: 7361.972351060356
Epoch: 240  Train Loss: 1588.6965184791816  Validation Loss: 11772.792381808134
Epoch: 250  Train Loss: 966.398641188182  Validation Loss: 6444.950165881209
Epoch: 260  Train Loss: 847.0523600115988  Validation Loss: 5354.405411572201
Epoch: 270  Train Loss: 1317.9429081650817  Validation Loss: 4715.815839970467
Epoch: 280  Train Loss: 1230.604370583913  Validation Loss: 7759.95164678987
Epoch: 290  Train Loss: 1017.6308235396936  Validation Loss: 4327.406070649959
Epoch: 300  Train Loss: 1340.75167258629  Validation Loss: 7455.299451557958
Epoch: 310  Train Loss: 865.4531149963444  Validation Loss: 3026.0756133087007
Epoch: 320  Train Loss: 1013.9034806339649  Validation Loss: 5143.530288218932
Epoch: 330  Train Loss: 1107.6849755798305  Validation Loss: 3543.2708522869593
Epoch: 340  Train Loss: 3160.001950881222  Validation Loss: 14789.568510881181
Epoch: 350  Train Loss: 1019.9163731156577  Validation Loss: 4332.73189786405
Epoch: 360  Train Loss: 809.7895045600757  Validation Loss: 4724.746714778638
Epoch: 370  Train Loss: 1126.957975798991  Validation Loss: 3982.8361234786867
Epoch: 380  Train Loss: 727.5931314831969  Validation Loss: 2676.3340690980044
Epoch: 390  Train Loss: 1081.4752354778623  Validation Loss: 8610.10565836601
Epoch: 400  Train Loss: 560.9459795774585  Validation Loss: 2175.7429908568297
Epoch: 410  Train Loss: 687.9309995670219  Validation Loss: 2130.507564261058
Epoch: 420  Train Loss: 658.4623070836882  Validation Loss: 3764.781894670548
Epoch: 430  Train Loss: 406.72651519584787  Validation Loss: 2539.279079427356
Epoch: 440  Train Loss: 449.5441337154529  Validation Loss: 2539.0430834635995
Epoch: 450  Train Loss: 625.8380597292302  Validation Loss: 2005.6214069301668
Epoch: 460  Train Loss: 430.57277077039186  Validation Loss: 2449.5034607122343
Epoch: 470  Train Loss: 436.27361438405313  Validation Loss: 2212.0315795166453
Epoch: 480  Train Loss: 511.21919426196524  Validation Loss: 4485.38273439172
Epoch: 490  Train Loss: 763.6755433805224  Validation Loss: 3514.985336414872
Epoch: 500  Train Loss: 339.3913778848313  Validation Loss: 2041.4002232932337
Epoch: 510  Train Loss: 360.93612890063037  Validation Loss: 1789.8475937365195
Epoch: 520  Train Loss: 682.8772732930447  Validation Loss: 3693.2975917247354
Epoch: 530  Train Loss: 400.61178019767976  Validation Loss: 2654.7658043983197
Epoch: 540  Train Loss: 348.40024311995484  Validation Loss: 1798.0380545124005
Epoch: 550  Train Loss: 429.0963535565802  Validation Loss: 2272.299711987062
Epoch: 560  Train Loss: 443.4458476520975  Validation Loss: 1729.4199530168894
Epoch: 570  Train Loss: 249.41147868897517  Validation Loss: 1866.953473793299
Epoch: 580  Train Loss: 398.40704084430325  Validation Loss: 1717.079511637292
Epoch: 590  Train Loss: 357.80710522241225  Validation Loss: 2126.919367704459
Epoch: 600  Train Loss: 340.02677799589827  Validation Loss: 1945.3412538194643
Epoch: 610  Train Loss: 387.14225330482196  Validation Loss: 1636.1266879994666
Epoch: 620  Train Loss: 431.7210079097911  Validation Loss: 1519.889133667655
Epoch: 630  Train Loss: 217.28289986666002  Validation Loss: 1522.3907820394156
Epoch: 640  Train Loss: 457.17588555571893  Validation Loss: 1681.1877204593754
Epoch: 650  Train Loss: 285.707382240967  Validation Loss: 1495.9014331374883
Epoch: 660  Train Loss: 276.5026650721831  Validation Loss: 1644.2898602615933
Epoch: 670  Train Loss: 754.1737562888453  Validation Loss: 2420.09456199089
Epoch: 680  Train Loss: 491.74733959916404  Validation Loss: 1934.524358229779
Epoch: 690  Train Loss: 403.65523476498066  Validation Loss: 2164.373704340379
Epoch: 700  Train Loss: 439.60920426339607  Validation Loss: 2321.4666249342213
Epoch: 710  Train Loss: 402.2937957429383  Validation Loss: 1499.1300697305946
Epoch: 720  Train Loss: 557.9215359534908  Validation Loss: 4298.967657101105
Epoch: 730  Train Loss: 246.94857604485523  Validation Loss: 2231.6667628348737
Epoch: 740  Train Loss: 380.06419177528096  Validation Loss: 1438.5858281010233
Epoch: 750  Train Loss: 232.42615081821432  Validation Loss: 1432.2848260779508
Epoch: 760  Train Loss: 276.23157750429624  Validation Loss: 2037.923736421834
Epoch: 770  Train Loss: 153.601989735589  Validation Loss: 1498.6987458500985
Epoch: 780  Train Loss: 293.70200027373454  Validation Loss: 1616.8399522982872
Epoch: 790  Train Loss: 515.3864413584124  Validation Loss: 1405.2537650179088
Epoch: 800  Train Loss: 306.91996454133556  Validation Loss: 1890.714748602901
Epoch: 810  Train Loss: 453.9850477933772  Validation Loss: 2136.60614279939
Epoch: 820  Train Loss: 369.9468186113806  Validation Loss: 1283.240939058933
Epoch: 830  Train Loss: 253.54196797950055  Validation Loss: 1770.116598091056
Epoch: 840  Train Loss: 365.8607594584312  Validation Loss: 2417.8469428303756
Epoch: 850  Train Loss: 449.3571119412411  Validation Loss: 1301.3889608157604
Epoch: 860  Train Loss: 528.4394315640219  Validation Loss: 1809.355178778489
Epoch: 870  Train Loss: 441.63807920290054  Validation Loss: 1632.7545093107897
Epoch: 880  Train Loss: 354.6473385787028  Validation Loss: 2230.9217988097253
Epoch: 890  Train Loss: 337.9219311658655  Validation Loss: 2297.822534683161
Epoch: 900  Train Loss: 802.3097833934967  Validation Loss: 1505.1872898896008
Epoch: 910  Train Loss: 295.95715034352867  Validation Loss: 1384.5758568569486
Epoch: 920  Train Loss: 228.74942732297347  Validation Loss: 1577.6893545693742
Epoch: 930  Train Loss: 205.96481038866432  Validation Loss: 1221.3460595840193
Epoch: 940  Train Loss: 278.7801836295321  Validation Loss: 2160.416454456828
Epoch: 950  Train Loss: 137.9084953741843  Validation Loss: 1451.5875312401574
Epoch: 960  Train Loss: 210.72855413353525  Validation Loss: 1501.3465014417218
Epoch: 970  Train Loss: 229.6985317506153  Validation Loss: 1308.538503740821
Epoch: 980  Train Loss: 316.4191184967147  Validation Loss: 1492.6729233534575
Epoch: 990  Train Loss: 379.82477624054906  Validation Loss: 3160.2398966561586
torch.Size([8100])
torch.Size([8100])
100
100
Average Test Loss (MSE) tensor(1197.5427, device='cuda:0', grad_fn=<DivBackward0>)