Time to play:
Loading lists of data
GST (500, 81, 31)
graph data Data(x=[81, 31], edge_index=[2, 324], y=[81], pos=[81, 2])
Epoch: 10  Train Loss: 85482.97848183452  Validation Loss: 70342.00206658058
Epoch: 20  Train Loss: 85391.67265503526  Validation Loss: 70220.6452404418
Epoch: 30  Train Loss: 85270.3786050731  Validation Loss: 70070.14049889971
Epoch: 40  Train Loss: 85079.1041890946  Validation Loss: 69728.30881087833
Epoch: 50  Train Loss: 84860.58791233531  Validation Loss: 69542.65705340795
Epoch: 60  Train Loss: 84502.56017855718  Validation Loss: 69074.84134018936
Epoch: 70  Train Loss: 84035.46113883848  Validation Loss: 68584.00890635092
Epoch: 80  Train Loss: 83430.8924550185  Validation Loss: 67637.90315476779
Epoch: 90  Train Loss: 82433.20552346708  Validation Loss: 66552.57443127924
Epoch: 100  Train Loss: 81195.35956930749  Validation Loss: 65419.94833564096
Epoch: 110  Train Loss: 79706.15726009618  Validation Loss: 63996.50984965204
Epoch: 120  Train Loss: 77861.78254543967  Validation Loss: 62076.32316807245
Epoch: 130  Train Loss: 75857.03860383092  Validation Loss: 59945.55598759245
Epoch: 140  Train Loss: 73578.60416821156  Validation Loss: 58136.64610267677
Epoch: 150  Train Loss: 71158.08154336979  Validation Loss: 56076.76344144865
Epoch: 160  Train Loss: 68448.30676007773  Validation Loss: 53877.695059420104
Epoch: 170  Train Loss: 65702.73197794823  Validation Loss: 51756.92988732841
Epoch: 180  Train Loss: 62395.603192064125  Validation Loss: 49459.216364911335
Epoch: 190  Train Loss: 59156.93083848921  Validation Loss: 47193.5356119157
Epoch: 200  Train Loss: 55760.68017335906  Validation Loss: 45175.09272623655
Epoch: 210  Train Loss: 54129.93265879913  Validation Loss: 43336.338079071946
Epoch: 220  Train Loss: 52537.63770291067  Validation Loss: 42578.640576123806
Epoch: 230  Train Loss: 48621.845621164095  Validation Loss: 41133.75975012265
Epoch: 240  Train Loss: 44451.133806058206  Validation Loss: 39589.6337756257
Epoch: 250  Train Loss: 40431.89426763037  Validation Loss: 38081.38241388562
Epoch: 260  Train Loss: 36803.83152022656  Validation Loss: 37110.3303401551
Epoch: 270  Train Loss: 33214.357120633176  Validation Loss: 36251.510114349716
Epoch: 280  Train Loss: 30157.580601037625  Validation Loss: 35715.541501682535
Epoch: 290  Train Loss: 26762.067362914062  Validation Loss: 35741.89365426602
Epoch: 300  Train Loss: 23936.38286472631  Validation Loss: 36038.718473498666
Epoch: 310  Train Loss: 21386.02514380985  Validation Loss: 35889.42466273052
Epoch: 320  Train Loss: 18975.390383730162  Validation Loss: 35871.30179479092
Epoch: 330  Train Loss: 17034.9143981937  Validation Loss: 35385.76758531894
Epoch: 340  Train Loss: 15295.891301306168  Validation Loss: 35011.60814690154
Epoch: 350  Train Loss: 13755.957512876432  Validation Loss: 34297.43836867596
Epoch: 360  Train Loss: 12400.015561911254  Validation Loss: 33156.06155654238
Epoch: 370  Train Loss: 11060.721029606744  Validation Loss: 31746.243033920236
Epoch: 380  Train Loss: 10850.775455518078  Validation Loss: 29510.946438404735
Epoch: 390  Train Loss: 9168.73042513927  Validation Loss: 26991.869141937208
Epoch: 400  Train Loss: 7857.383529317031  Validation Loss: 24000.385139499147
Epoch: 410  Train Loss: 6614.886205711773  Validation Loss: 20132.615757721353
Epoch: 420  Train Loss: 6046.23804926544  Validation Loss: 17755.621898033958
Epoch: 430  Train Loss: 5260.682699793112  Validation Loss: 16568.577025385086
Epoch: 440  Train Loss: 4375.0314139181  Validation Loss: 15214.364009460656
Epoch: 450  Train Loss: 3988.809282330099  Validation Loss: 14860.33430052857
Epoch: 460  Train Loss: 3353.3990386298556  Validation Loss: 14262.04235549922
Epoch: 470  Train Loss: 2747.8813471228136  Validation Loss: 13727.316865246821
Epoch: 480  Train Loss: 2822.4064441485766  Validation Loss: 12901.936726139327
Epoch: 490  Train Loss: 2259.1849458268584  Validation Loss: 12592.84416238637
Epoch: 500  Train Loss: 1938.2406019923176  Validation Loss: 12497.54183973599
Epoch: 510  Train Loss: 1866.4514485062862  Validation Loss: 11701.45844831147
Epoch: 520  Train Loss: 1585.54726057206  Validation Loss: 11199.51651570699
Epoch: 530  Train Loss: 1630.675737393719  Validation Loss: 10751.152850055769
Epoch: 540  Train Loss: 1357.29759345756  Validation Loss: 10270.592190364314
Epoch: 550  Train Loss: 1273.860285700018  Validation Loss: 9653.545410118257
Epoch: 560  Train Loss: 1210.1682851255307  Validation Loss: 9283.138789921653
Epoch: 570  Train Loss: 1182.0365502936029  Validation Loss: 8775.061764341825
Epoch: 580  Train Loss: 1250.840465354696  Validation Loss: 8279.764561837206
Epoch: 590  Train Loss: 1224.6890329969972  Validation Loss: 7588.058243835236
Epoch: 600  Train Loss: 1282.2218674634757  Validation Loss: 7111.317636295123
Epoch: 610  Train Loss: 811.9981992175921  Validation Loss: 6582.0928869530535
Epoch: 620  Train Loss: 785.5771609124239  Validation Loss: 6125.292884981219
Epoch: 630  Train Loss: 812.1802973505072  Validation Loss: 5719.208880719567
Epoch: 640  Train Loss: 836.2215884572671  Validation Loss: 5241.163035731707
Epoch: 650  Train Loss: 782.5742800721481  Validation Loss: 4857.536837565509
Epoch: 660  Train Loss: 903.8664681406827  Validation Loss: 4403.290732240624
Epoch: 670  Train Loss: 1058.6240584130915  Validation Loss: 3971.8697133379055
Epoch: 680  Train Loss: 690.499379387791  Validation Loss: 3691.847924817807
Epoch: 690  Train Loss: 717.1239651439255  Validation Loss: 3433.551369316745
Epoch: 700  Train Loss: 584.9957831654433  Validation Loss: 3263.0340809103377
Epoch: 710  Train Loss: 781.9196978580103  Validation Loss: 3173.841231929008
Epoch: 720  Train Loss: 647.1066653222224  Validation Loss: 2959.63461250956
Epoch: 730  Train Loss: 531.1972840654738  Validation Loss: 2915.640373835276
Epoch: 740  Train Loss: 608.293045812385  Validation Loss: 2831.8249330743292
Epoch: 750  Train Loss: 492.0964549033485  Validation Loss: 3608.994583476257
Epoch: 760  Train Loss: 893.0157684708923  Validation Loss: 2913.9343704992225
Epoch: 770  Train Loss: 696.7788383114638  Validation Loss: 2759.722601321526
Epoch: 780  Train Loss: 495.06749836253175  Validation Loss: 2964.753886982523
Epoch: 790  Train Loss: 577.3859837688416  Validation Loss: 2703.2648066456763
Epoch: 800  Train Loss: 779.1178198170277  Validation Loss: 2745.282640036642
Epoch: 810  Train Loss: 495.5484633230805  Validation Loss: 2738.4313687470544
Epoch: 820  Train Loss: 682.7164179849891  Validation Loss: 2609.539519142056
Epoch: 830  Train Loss: 491.7682107678927  Validation Loss: 2626.592649455699
Epoch: 840  Train Loss: 584.8048756065585  Validation Loss: 2428.520949752049
Epoch: 850  Train Loss: 681.5758140217507  Validation Loss: 2871.6498854840465
Epoch: 860  Train Loss: 464.18132411430537  Validation Loss: 2272.371035909997
Epoch: 870  Train Loss: 398.4447981348573  Validation Loss: 2161.2231413113705
Epoch: 880  Train Loss: 476.3831795570907  Validation Loss: 2123.0291413280925
Epoch: 890  Train Loss: 492.6484293092262  Validation Loss: 2278.749734232431
Epoch: 900  Train Loss: 461.0007627438858  Validation Loss: 2045.7861494441815
Epoch: 910  Train Loss: 421.9577165445318  Validation Loss: 2190.146468328214
Epoch: 920  Train Loss: 407.1012724556106  Validation Loss: 1996.896659821884
Epoch: 930  Train Loss: 549.4783949812693  Validation Loss: 2112.8265444154513
Epoch: 940  Train Loss: 711.4217238309185  Validation Loss: 2049.705188206061
Epoch: 950  Train Loss: 1007.052786465401  Validation Loss: 2957.4848330076425
Epoch: 960  Train Loss: 562.0094082040968  Validation Loss: 1961.7075535882816
Epoch: 970  Train Loss: 475.67389310989483  Validation Loss: 1830.8621290604951
Epoch: 980  Train Loss: 372.86177692560324  Validation Loss: 1761.953243676194
Epoch: 990  Train Loss: 323.49183733710794  Validation Loss: 2321.9922496667778
torch.Size([8100])
torch.Size([8100])
100
100
Average Test Loss (MSE) tensor(2632.6667, device='cuda:0', grad_fn=<DivBackward0>)