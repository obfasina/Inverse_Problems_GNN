Time to play:
Loading lists of data
graph data Data(x=[81, 1], edge_index=[2, 324], y=[81], pos=[81, 2])
Epoch: 10  Train Loss: 83814.44025411949  Validation Loss: 81799.56467501882
Epoch: 20  Train Loss: 82772.01565321609  Validation Loss: 79953.98739960874
Epoch: 30  Train Loss: 80681.49320673528  Validation Loss: 75905.91684515565
Epoch: 40  Train Loss: 76708.6529743446  Validation Loss: 69893.02046843478
Epoch: 50  Train Loss: 70574.62599540544  Validation Loss: 59774.15854298066
Epoch: 60  Train Loss: 62869.4615423259  Validation Loss: 51670.75913979991
Epoch: 70  Train Loss: 53228.696723598194  Validation Loss: 45741.26870203504
Epoch: 80  Train Loss: 43475.097889944496  Validation Loss: 43758.132330729386
Epoch: 90  Train Loss: 34528.77055312027  Validation Loss: 44963.74571914996
torch.Size([8100])
torch.Size([8100])
100
100
[[161.68588   292.       ]
 [ 41.14708   135.       ]
 [194.91093   333.       ]
 [169.70895   302.       ]
 [112.28896   230.       ]
 [ 74.094666  181.       ]
 [ 68.94514   174.       ]
 [ 54.547974  154.       ]
 [287.23364   443.       ]
 [124.18958   245.       ]
 [  3.4683785   2.       ]
 [  3.4683785  12.       ]
 [  8.537102   78.       ]
 [  3.4683785   6.       ]
 [316.68378   478.       ]
 [  3.4542248  39.       ]
 [  7.238485   75.       ]
 [ 74.8347    182.       ]
 [ 80.06058   189.       ]
 [186.6929    323.       ]
 [264.52127   416.       ]
 [122.60279   243.       ]
 [163.28874   294.       ]
 [246.02971   394.       ]
 [128.96837   251.       ]
 [ 75.575554  183.       ]
 [ 58.12505   159.       ]
 [239.30707   386.       ]
 [ 33.91813   124.       ]
 [327.627     491.       ]
 [ 96.45284   210.       ]
 [261.15768   412.       ]
 [ 94.082016  207.       ]
 [252.75262   402.       ]
 [295.64603   453.       ]
 [241.82796   389.       ]
 [  3.4683785   0.       ]
 [  7.66695    76.       ]
 [183.43675   319.       ]
 [261.99844   413.       ]
 [167.29903   299.       ]
 [109.11743   226.       ]
 [328.4688    492.       ]
 [  3.4324596  44.       ]
 [ 42.530712  137.       ]
 [ 53.121014  152.       ]
 [214.1132    356.       ]
 [  6.4014273  73.       ]
 [168.10194   300.       ]
 [ 23.736307  107.       ]
 [313.317     474.       ]
 [306.58432   466.       ]
 [314.15866   475.       ]
 [ 10.762356   83.       ]
 [ 60.992924  163.       ]
 [ 35.783512  127.       ]
 [325.94342   489.       ]
 [296.4873    454.       ]
 [262.83932   414.       ]
 [187.50957   324.       ]
 [110.70302   228.       ]
 [  3.4683785  14.       ]
 [310.79218   471.       ]
 [160.88472   291.       ]
 [229.22595   374.       ]
 [  3.4683785  23.       ]
 [204.06467   344.       ]
 [ 83.10589   193.       ]
 [ 92.50431   205.       ]
 [214.95233   357.       ]
 [ 64.58776   168.       ]
 [  3.4553475  38.       ]
 [265.36234   417.       ]
 [259.47607   410.       ]
 [272.93317   426.       ]
 [  3.4461691  43.       ]
 [ 66.759445  171.       ]
 [148.1007    275.       ]
 [ 82.33888   192.       ]
 [107.53277   224.       ]
 [ 24.326092  108.       ]
 [  3.4637096  32.       ]
 [ 25.51337   110.       ]
 [202.39525   342.       ]
 [249.39111   398.       ]
 [106.74065   223.       ]
 [275.45703   429.       ]
 [101.19859   216.       ]
 [ 47.433342  144.       ]
 [178.57634   313.       ]
 [  3.4532537  40.       ]
 [  3.4683785  18.       ]
 [  3.46377    59.       ]
 [196.56834   335.       ]
 [  3.4683785   3.       ]
 [ 45.316177  141.       ]
 [  4.1615486  66.       ]
 [307.42587   467.       ]
 [ 27.302113  113.       ]
 [ 26.108652  111.       ]]
Average Test Loss (MSE) tensor(44064.3945, device='cuda:0', grad_fn=<DivBackward0>)