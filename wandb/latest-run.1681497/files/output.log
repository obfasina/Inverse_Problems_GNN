Time to play:
Loading lists of data
graph data Data(x=[81, 1], edge_index=[2, 324], y=[81], pos=[81, 2])
Epoch: 10  Train Loss: 83828.55913750418  Validation Loss: 81947.24514348875
Epoch: 20  Train Loss: 82729.12265130358  Validation Loss: 79085.07431100475
Epoch: 30  Train Loss: 80345.78173695602  Validation Loss: 75291.85796859529
Epoch: 40  Train Loss: 76242.86122080857  Validation Loss: 68798.31689984257
Epoch: 50  Train Loss: 69989.1819694791  Validation Loss: 61228.812545972214
Epoch: 60  Train Loss: 61567.07437718674  Validation Loss: 52957.37787708861
Epoch: 70  Train Loss: 51544.98031792648  Validation Loss: 46365.81904592359
Epoch: 80  Train Loss: 40738.644299254665  Validation Loss: 43755.65969744274
Epoch: 90  Train Loss: 30765.80337763761  Validation Loss: 44907.40649664605
Epoch: 100  Train Loss: 22810.135636927123  Validation Loss: 46256.09978486862
Epoch: 110  Train Loss: 16371.840089866368  Validation Loss: 45638.49581501069
Epoch: 120  Train Loss: 9236.83777120694  Validation Loss: 41428.23882989268
Epoch: 130  Train Loss: 5136.9015582191  Validation Loss: 37696.97410021274
Epoch: 140  Train Loss: 3339.150856140556  Validation Loss: 36523.7284519066
Epoch: 150  Train Loss: 1967.734547379916  Validation Loss: 35206.20998839069
Epoch: 160  Train Loss: 1735.7791294114731  Validation Loss: 35340.73602817594
Epoch: 170  Train Loss: 1868.3143645523662  Validation Loss: 37746.24388882044
Epoch: 180  Train Loss: 1604.3493875443057  Validation Loss: 29098.92820466257
Epoch: 190  Train Loss: 1334.8925053608584  Validation Loss: 28741.41727802685
Epoch: 200  Train Loss: 2045.9920029701082  Validation Loss: 27519.621821705423
Epoch: 210  Train Loss: 2045.429304344535  Validation Loss: 25475.319022798063
Epoch: 220  Train Loss: 2279.7559377365455  Validation Loss: 26841.038287115356
Epoch: 230  Train Loss: 1827.7892722589768  Validation Loss: 17461.14950343808
Epoch: 240  Train Loss: 1593.2363679754324  Validation Loss: 19414.37061676414
Epoch: 250  Train Loss: 2493.8525433079053  Validation Loss: 8673.013666266297
Epoch: 260  Train Loss: 1467.0087105187013  Validation Loss: 8385.039340209736
Epoch: 270  Train Loss: 1294.0849639870391  Validation Loss: 8923.827609715421
Epoch: 280  Train Loss: 1268.5547592184078  Validation Loss: 6142.593329775618
Epoch: 290  Train Loss: 971.6178225012646  Validation Loss: 6511.962721545684
Epoch: 300  Train Loss: 981.1750862627472  Validation Loss: 4987.395818511489
Epoch: 310  Train Loss: 1330.8025451035458  Validation Loss: 3860.440980597435
Epoch: 320  Train Loss: 1137.7420779628253  Validation Loss: 6036.6590866091365
Epoch: 330  Train Loss: 1211.6259911457855  Validation Loss: 3695.7198924749437
Epoch: 340  Train Loss: 928.9718399299627  Validation Loss: 6807.936254227079
Epoch: 350  Train Loss: 1316.3652291210776  Validation Loss: 6062.587726957005
Epoch: 360  Train Loss: 977.2475942268811  Validation Loss: 4182.080496144473
Epoch: 370  Train Loss: 670.7881626718062  Validation Loss: 2808.9460084220914
Epoch: 380  Train Loss: 803.5108324315592  Validation Loss: 3668.6325167506043
Epoch: 390  Train Loss: 988.5178484566541  Validation Loss: 3447.4510671629187
Epoch: 400  Train Loss: 620.4486163958514  Validation Loss: 3101.7378314254297
Epoch: 410  Train Loss: 652.0322955450553  Validation Loss: 2590.845893784087
Epoch: 420  Train Loss: 802.2977759495438  Validation Loss: 2914.045745643184
Epoch: 430  Train Loss: 667.4163543333781  Validation Loss: 2587.7477941860857
Epoch: 440  Train Loss: 649.4838610580517  Validation Loss: 3388.715777993264
Epoch: 450  Train Loss: 462.9343150318053  Validation Loss: 3175.070452281921
Epoch: 460  Train Loss: 686.1333184072722  Validation Loss: 3700.6683889099363
Epoch: 470  Train Loss: 559.2471421665806  Validation Loss: 2087.977715411427
Epoch: 480  Train Loss: 828.2578229246634  Validation Loss: 4456.543501134322
Epoch: 490  Train Loss: 586.4668017835625  Validation Loss: 2196.0327325387225
Epoch: 500  Train Loss: 550.6872418694314  Validation Loss: 2383.589895317153
Epoch: 510  Train Loss: 517.3295981763566  Validation Loss: 3493.529541136206
Epoch: 520  Train Loss: 518.9358047039846  Validation Loss: 2076.82334851952
Epoch: 530  Train Loss: 379.43974032263367  Validation Loss: 1831.9987970963543
Epoch: 540  Train Loss: 694.1114102237583  Validation Loss: 2861.00875199151
Epoch: 550  Train Loss: 349.8498904078062  Validation Loss: 2026.8399591544517
Epoch: 560  Train Loss: 960.8569227572569  Validation Loss: 3441.8261234124006
Epoch: 570  Train Loss: 376.6873850661209  Validation Loss: 1774.967824864141
Epoch: 580  Train Loss: 381.9252843438514  Validation Loss: 2132.113033452948
Epoch: 590  Train Loss: 892.6931953622792  Validation Loss: 2203.0743562662074
Epoch: 600  Train Loss: 355.481929348438  Validation Loss: 2071.3528260278
Epoch: 610  Train Loss: 460.35640166212903  Validation Loss: 3101.6601753811315
Epoch: 620  Train Loss: 642.7007841932143  Validation Loss: 2517.658328128594
Epoch: 630  Train Loss: 405.3127717441235  Validation Loss: 2323.4289816778696
Epoch: 640  Train Loss: 434.2968591190094  Validation Loss: 1689.9153966560198
Epoch: 650  Train Loss: 603.2184864787893  Validation Loss: 3429.44287303499
Epoch: 660  Train Loss: 524.581469735047  Validation Loss: 1710.4872788706239
Epoch: 670  Train Loss: 591.1872631040176  Validation Loss: 1855.6434857680645
Epoch: 680  Train Loss: 438.5812013626234  Validation Loss: 4794.799667430519
Epoch: 690  Train Loss: 260.1355841056825  Validation Loss: 1865.9495383868893
Epoch: 700  Train Loss: 330.7198651323053  Validation Loss: 2832.6870742008246
Epoch: 710  Train Loss: 558.4214953768256  Validation Loss: 3577.0069607592686
Epoch: 720  Train Loss: 476.4608681330242  Validation Loss: 2450.3715609825613
Epoch: 730  Train Loss: 362.94017901701886  Validation Loss: 2139.7360487309634
Epoch: 740  Train Loss: 402.269133665811  Validation Loss: 3160.1038392233986
Epoch: 750  Train Loss: 432.3916213171818  Validation Loss: 2543.0056500281726
Epoch: 760  Train Loss: 287.35306996268406  Validation Loss: 1808.7156882796041
Epoch: 770  Train Loss: 337.03925922846184  Validation Loss: 1512.500915665077
Epoch: 780  Train Loss: 278.8712100153362  Validation Loss: 1588.4180075469685
Epoch: 790  Train Loss: 521.3036668211531  Validation Loss: 6196.510081713389
Epoch: 800  Train Loss: 711.3296826724996  Validation Loss: 4332.6020055371
Epoch: 810  Train Loss: 309.08320058372107  Validation Loss: 2320.6375429134678
Epoch: 820  Train Loss: 227.75643377203733  Validation Loss: 1524.9617285439988
Epoch: 830  Train Loss: 307.75748183705264  Validation Loss: 2174.090481171871
Epoch: 840  Train Loss: 210.3067748423192  Validation Loss: 1483.204070926057
Epoch: 850  Train Loss: 443.7200425222192  Validation Loss: 1986.9384529181289
Epoch: 860  Train Loss: 374.30904733192006  Validation Loss: 1640.0611865327448
Epoch: 870  Train Loss: 493.59550091033026  Validation Loss: 1867.6438553387952
Epoch: 880  Train Loss: 332.1381024018946  Validation Loss: 1438.1554037534804
Epoch: 890  Train Loss: 279.23184498253323  Validation Loss: 1562.3668470168282
Epoch: 900  Train Loss: 240.73782761868827  Validation Loss: 1605.094549889313
Epoch: 910  Train Loss: 490.57598928132353  Validation Loss: 1702.5599449859528
Epoch: 920  Train Loss: 298.7206096262981  Validation Loss: 1568.6097185604292
Epoch: 930  Train Loss: 444.9479163255546  Validation Loss: 1758.570868574826
Epoch: 940  Train Loss: 342.6747646896381  Validation Loss: 1560.4243197536089
Epoch: 950  Train Loss: 204.32961153576505  Validation Loss: 2331.3875283016237
Epoch: 960  Train Loss: 262.014244139111  Validation Loss: 1371.7620374642227
Epoch: 970  Train Loss: 419.5343486994668  Validation Loss: 1940.477152290003
Epoch: 980  Train Loss: 299.0303003147709  Validation Loss: 1586.419204038258
Epoch: 990  Train Loss: 193.7247260322216  Validation Loss: 2707.159767717561
torch.Size([8100])
torch.Size([8100])
100
100
Average Test Loss (MSE) tensor(1352.6154, device='cuda:0', grad_fn=<DivBackward0>)