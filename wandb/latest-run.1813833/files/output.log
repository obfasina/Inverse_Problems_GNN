Time to play:
Loading lists of data
GST (500, 81, 31)
graph data Data(x=[81, 31], edge_index=[2, 324], y=[81], pos=[81, 2])
Epoch: 10  Train Loss: 83784.38749838801  Validation Loss: 67927.38736220592
Epoch: 20  Train Loss: 77185.57396007552  Validation Loss: 61625.59093023878
Epoch: 30  Train Loss: 62376.91366456705  Validation Loss: 51338.61877559634
Epoch: 40  Train Loss: 39590.35776027444  Validation Loss: 42628.30570699028
Epoch: 50  Train Loss: 18821.302170947733  Validation Loss: 42440.14193156243
Epoch: 60  Train Loss: 8570.531469489551  Validation Loss: 43145.75644959198
Epoch: 70  Train Loss: 4014.0943740086236  Validation Loss: 40648.31906967568
Epoch: 80  Train Loss: 3101.385146414137  Validation Loss: 34244.228417047074
Epoch: 90  Train Loss: 3106.2033994910557  Validation Loss: 29186.50784418909
Epoch: 100  Train Loss: 2905.5583405374273  Validation Loss: 29285.047760798683
Epoch: 110  Train Loss: 2676.4085871664975  Validation Loss: 32055.205778490028
Epoch: 120  Train Loss: 5259.578308787859  Validation Loss: 31439.746301132524
Epoch: 130  Train Loss: 2569.447858823844  Validation Loss: 23697.525896970947
Epoch: 140  Train Loss: 2691.045185027762  Validation Loss: 30649.94334348393
Epoch: 150  Train Loss: 2661.3792799788157  Validation Loss: 20399.55581812132
Epoch: 160  Train Loss: 2729.7531126444687  Validation Loss: 28887.420273871634
Epoch: 170  Train Loss: 2392.5010864632463  Validation Loss: 19155.177848107916
Epoch: 180  Train Loss: 2508.9602945309225  Validation Loss: 22071.11949992907
Epoch: 190  Train Loss: 2651.9996547347664  Validation Loss: 22442.101324505617
Epoch: 200  Train Loss: 5394.363481234425  Validation Loss: 18742.278076146027
Epoch: 210  Train Loss: 2141.60270043479  Validation Loss: 12446.60609371011
Epoch: 220  Train Loss: 2466.6451802134693  Validation Loss: 11163.75823535864
Epoch: 230  Train Loss: 2530.5380167306544  Validation Loss: 14535.328344127784
Epoch: 240  Train Loss: 2398.7006775337563  Validation Loss: 20536.43381713185
Epoch: 250  Train Loss: 2507.3239575795187  Validation Loss: 10338.4379473932
Epoch: 260  Train Loss: 2905.9005064073026  Validation Loss: 23550.325184876387
Epoch: 270  Train Loss: 2086.7793427365505  Validation Loss: 8769.503515039398
Epoch: 280  Train Loss: 2643.4003107621215  Validation Loss: 21259.509818384293
Epoch: 290  Train Loss: 2204.5044494941376  Validation Loss: 5227.727823274297
Epoch: 300  Train Loss: 2100.6923447485506  Validation Loss: 4803.921089293476
Epoch: 310  Train Loss: 1870.5588659424277  Validation Loss: 4360.522717623084
Epoch: 320  Train Loss: 1958.628491827658  Validation Loss: 8303.760102602426
Epoch: 330  Train Loss: 1819.4925398113508  Validation Loss: 3745.587564953731
Epoch: 340  Train Loss: 2003.5735675747803  Validation Loss: 3471.952730532042
Epoch: 350  Train Loss: 1840.778922024132  Validation Loss: 3438.376964600514
Epoch: 360  Train Loss: 2218.1655254221537  Validation Loss: 3934.7547419579964
Epoch: 370  Train Loss: 1684.2196609007394  Validation Loss: 4323.0016094182765
Epoch: 380  Train Loss: 1804.7867790433454  Validation Loss: 3979.3475831174023
Epoch: 390  Train Loss: 2015.3587405897895  Validation Loss: 5991.453754553293
Epoch: 400  Train Loss: 1635.283507236967  Validation Loss: 3846.6708837799247
Epoch: 410  Train Loss: 1629.9181748999508  Validation Loss: 3743.8551527629766
Epoch: 420  Train Loss: 1657.3336337630942  Validation Loss: 2844.2849486366895
Epoch: 430  Train Loss: 1508.0072993132853  Validation Loss: 3129.4396953144865
Epoch: 440  Train Loss: 1663.4145083155709  Validation Loss: 5682.451772626088
Epoch: 450  Train Loss: 1542.8772504833826  Validation Loss: 2701.8344520298906
Epoch: 460  Train Loss: 1768.4477934860709  Validation Loss: 3250.1277838278506
Epoch: 470  Train Loss: 3786.3450342080723  Validation Loss: 7370.028048427274
Epoch: 480  Train Loss: 2037.6422873578194  Validation Loss: 3594.156227335025
Epoch: 490  Train Loss: 2387.2440648876636  Validation Loss: 2931.9519450776775
Epoch: 500  Train Loss: 1670.178175793147  Validation Loss: 3419.3467122947077
Epoch: 510  Train Loss: 1318.5946748262402  Validation Loss: 2524.541049833545
Epoch: 520  Train Loss: 1597.3328411478244  Validation Loss: 2717.7210260284223
Epoch: 530  Train Loss: 1227.0566890020855  Validation Loss: 2629.2243669555273
Epoch: 540  Train Loss: 1152.9144649933678  Validation Loss: 3536.978454092488
Epoch: 550  Train Loss: 1439.0256970215526  Validation Loss: 3530.4832271373866
Epoch: 560  Train Loss: 1389.642840658211  Validation Loss: 2957.515786751344
Epoch: 570  Train Loss: 1219.0361121440017  Validation Loss: 3260.0178023866124
Epoch: 580  Train Loss: 1244.6991833499687  Validation Loss: 4617.434719911013
Epoch: 590  Train Loss: 1009.2470105535125  Validation Loss: 2446.1811176544797
Epoch: 600  Train Loss: 1093.4113507360914  Validation Loss: 3213.8127341286554
Epoch: 610  Train Loss: 1112.969666853789  Validation Loss: 2201.1300245076022
Epoch: 620  Train Loss: 1137.1027658320957  Validation Loss: 2315.9352335256795
Epoch: 630  Train Loss: 1903.9211578304446  Validation Loss: 2190.074366360159
Epoch: 640  Train Loss: 986.2610234315081  Validation Loss: 1804.9671065522891
Epoch: 650  Train Loss: 819.1934665979651  Validation Loss: 1977.8391989016602
Epoch: 660  Train Loss: 790.2994225843539  Validation Loss: 2698.4079124175355
Epoch: 670  Train Loss: 900.4820530573897  Validation Loss: 1797.3651101484622
Epoch: 680  Train Loss: 813.6549266296232  Validation Loss: 1815.022634256094
Epoch: 690  Train Loss: 1283.4847610721679  Validation Loss: 1911.4093775011465
Epoch: 700  Train Loss: 1160.4632160751123  Validation Loss: 5549.793810598495
/home/dami/anaconda3/envs/fenics_d/lib/python3.10/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([8100, 31])) that is different to the input size (torch.Size([8100, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
