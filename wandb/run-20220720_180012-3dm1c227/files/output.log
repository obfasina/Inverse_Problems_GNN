Time to play:
Loading lists of data
graph data Data(x=[81, 1], edge_index=[2, 324], y=[81], pos=[81, 2])
Epoch: 10  Train Loss: 83590.97294433106  Validation Loss: 81242.19755718944
Epoch: 20  Train Loss: 82331.16076164744  Validation Loss: 78184.11764003239
Epoch: 30  Train Loss: 79799.0564680915  Validation Loss: 73088.84066216639
Epoch: 40  Train Loss: 75463.19083308573  Validation Loss: 68006.13772087148
Epoch: 50  Train Loss: 69008.15858284697  Validation Loss: 59530.81386413852
Epoch: 60  Train Loss: 60411.20168248373  Validation Loss: 51068.77878889394
Epoch: 70  Train Loss: 50828.77816381661  Validation Loss: 44854.54328020938
Epoch: 80  Train Loss: 41723.06776197418  Validation Loss: 43917.880190365184
Epoch: 90  Train Loss: 34008.02825766612  Validation Loss: 45507.41994032377
Epoch: 100  Train Loss: 28308.32245102397  Validation Loss: 46054.38404455257
Epoch: 110  Train Loss: 24397.88782740064  Validation Loss: 45989.87955796816
Epoch: 120  Train Loss: 21297.292784101115  Validation Loss: 43392.57944443245
Epoch: 130  Train Loss: 17601.46592035277  Validation Loss: 39590.48537594896
Epoch: 140  Train Loss: 13385.754350833136  Validation Loss: 33539.07321160606
Epoch: 150  Train Loss: 11076.435597381678  Validation Loss: 22093.50327540336
Epoch: 160  Train Loss: 8952.424887891799  Validation Loss: 20691.509850297938
Epoch: 170  Train Loss: 5446.158504501417  Validation Loss: 18713.69126267142
Epoch: 180  Train Loss: 3752.2273214971015  Validation Loss: 20478.99083553797
Epoch: 190  Train Loss: 3610.541916967208  Validation Loss: 15553.014271944614
Epoch: 200  Train Loss: 3356.5025394833488  Validation Loss: 10303.898873899569
Epoch: 210  Train Loss: 2014.185511952175  Validation Loss: 8625.755480731366
Epoch: 220  Train Loss: 1978.2578996666605  Validation Loss: 15276.358072124667
Epoch: 230  Train Loss: 4861.305879906344  Validation Loss: 25622.773720733658
Epoch: 240  Train Loss: 3517.036891243622  Validation Loss: 5981.253811008765
Epoch: 250  Train Loss: 1803.764047307569  Validation Loss: 13145.346694254058
Epoch: 260  Train Loss: 1225.3565987396098  Validation Loss: 3737.5587639132546
Epoch: 270  Train Loss: 1593.1756233671497  Validation Loss: 5221.6213724314675
Epoch: 280  Train Loss: 1001.2139483635416  Validation Loss: 3418.066054996318
Epoch: 290  Train Loss: 1288.1344594102266  Validation Loss: 3258.5378105068903
Epoch: 300  Train Loss: 1056.4866185572216  Validation Loss: 3210.1946453673254
Epoch: 310  Train Loss: 2155.899077967744  Validation Loss: 7113.245719295684
Epoch: 320  Train Loss: 1128.036305660203  Validation Loss: 3826.331010244363
Epoch: 330  Train Loss: 973.4840944825452  Validation Loss: 4474.478436115684
Epoch: 340  Train Loss: 1044.5476918276167  Validation Loss: 3575.885526118689
Epoch: 350  Train Loss: 783.3689957549699  Validation Loss: 3030.419565771397
Epoch: 360  Train Loss: 794.2976999598001  Validation Loss: 4155.710040788399
Epoch: 370  Train Loss: 1008.2324593309685  Validation Loss: 2927.711937722324
Epoch: 380  Train Loss: 949.0192204393417  Validation Loss: 2947.2793934647657
Epoch: 390  Train Loss: 1418.4601722107263  Validation Loss: 3319.9817685520293
Epoch: 400  Train Loss: 890.4680261988307  Validation Loss: 2635.1760129535023
Epoch: 410  Train Loss: 781.064605654455  Validation Loss: 4562.512475572402
Epoch: 420  Train Loss: 974.1946982207764  Validation Loss: 3581.474822672503
Epoch: 430  Train Loss: 761.0174014663107  Validation Loss: 4873.443722845153
Epoch: 440  Train Loss: 898.7556197547973  Validation Loss: 3048.4848178189395
Epoch: 450  Train Loss: 927.7507074512  Validation Loss: 2430.3235487765496
Epoch: 460  Train Loss: 757.757526998185  Validation Loss: 2627.86955742983
Epoch: 470  Train Loss: 886.5250472344156  Validation Loss: 3061.7206133504337
Epoch: 480  Train Loss: 765.2450958534137  Validation Loss: 2829.08945105721
Epoch: 490  Train Loss: 827.898649257278  Validation Loss: 2942.315156946434
Epoch: 500  Train Loss: 847.0268438600475  Validation Loss: 3528.496678631172
Epoch: 510  Train Loss: 798.7325177064771  Validation Loss: 2430.0639898259406
Epoch: 520  Train Loss: 709.8994911406794  Validation Loss: 2978.1652283724343
Epoch: 530  Train Loss: 600.5097996797897  Validation Loss: 2786.589235925063
Epoch: 540  Train Loss: 598.5180040343082  Validation Loss: 3608.5662825244267
Epoch: 550  Train Loss: 901.0426681002428  Validation Loss: 3336.014844452565
Epoch: 560  Train Loss: 710.7468707210154  Validation Loss: 2270.8444006082295
Epoch: 570  Train Loss: 808.4362996232157  Validation Loss: 1981.1432679268057
Epoch: 580  Train Loss: 578.7660650334457  Validation Loss: 2153.5539432970395
Epoch: 590  Train Loss: 719.9175918176505  Validation Loss: 3617.875052012034
Epoch: 600  Train Loss: 1272.495017027141  Validation Loss: 5056.074625758173
Epoch: 610  Train Loss: 613.0698765334286  Validation Loss: 2042.3333690772317
Epoch: 620  Train Loss: 704.7856023342547  Validation Loss: 2440.4461095054216
Epoch: 630  Train Loss: 869.6466414979659  Validation Loss: 1904.5681077347067
Epoch: 640  Train Loss: 562.7772759419443  Validation Loss: 1846.0866019938662
Epoch: 650  Train Loss: 749.1260370089457  Validation Loss: 3986.1626119182442
Epoch: 660  Train Loss: 1477.1603683242959  Validation Loss: 9366.173113695906
Epoch: 670  Train Loss: 780.3767104682433  Validation Loss: 2971.9623481469466
Epoch: 680  Train Loss: 726.0819641088375  Validation Loss: 1953.2625519547428
Epoch: 690  Train Loss: 817.8511107781233  Validation Loss: 2304.0132506782634
Epoch: 700  Train Loss: 530.3742090093497  Validation Loss: 1915.4494784857332
Epoch: 710  Train Loss: 804.5387434762873  Validation Loss: 2095.2522784367934
Epoch: 720  Train Loss: 747.2438927752029  Validation Loss: 2103.3512889751046
Epoch: 730  Train Loss: 645.4784287160437  Validation Loss: 3084.469254609995
Epoch: 740  Train Loss: 620.5083235985245  Validation Loss: 2651.408483642162
Epoch: 750  Train Loss: 625.3786079385308  Validation Loss: 1614.3643703583227
Epoch: 760  Train Loss: 594.1975659418684  Validation Loss: 1749.9108525573872
Epoch: 770  Train Loss: 527.1308736877828  Validation Loss: 1652.1112116559582
Epoch: 780  Train Loss: 634.9676716720375  Validation Loss: 1594.4042457546755
Epoch: 790  Train Loss: 725.2605431194893  Validation Loss: 1655.5583194204128
Epoch: 800  Train Loss: 560.4111785698271  Validation Loss: 2111.3971246721453
Epoch: 810  Train Loss: 604.1180371725936  Validation Loss: 1941.315700597334
Epoch: 820  Train Loss: 561.1371440837285  Validation Loss: 2422.1104922367367
Epoch: 830  Train Loss: 500.73149922235297  Validation Loss: 1518.3991081041672
Epoch: 840  Train Loss: 604.9554287263403  Validation Loss: 2307.7133876553976
Epoch: 850  Train Loss: 810.3856107515518  Validation Loss: 1473.2889162997194
Epoch: 860  Train Loss: 715.9474407111866  Validation Loss: 1564.4179957226481
Epoch: 870  Train Loss: 427.4605005615613  Validation Loss: 2008.6360009579384
Epoch: 880  Train Loss: 516.1341724191324  Validation Loss: 2316.2705809764157
Epoch: 890  Train Loss: 629.3798340387788  Validation Loss: 1400.3497880044797
Epoch: 900  Train Loss: 442.90421040589376  Validation Loss: 1461.3928488347854
Epoch: 910  Train Loss: 606.1680216171072  Validation Loss: 1325.7397542841024
Epoch: 920  Train Loss: 390.47688355890773  Validation Loss: 1344.1066018494023
Epoch: 930  Train Loss: 566.2723348701636  Validation Loss: 2300.8184931634996
Epoch: 940  Train Loss: 465.8550349896307  Validation Loss: 1585.9551605720424
Epoch: 950  Train Loss: 632.5677477882656  Validation Loss: 1462.2275476683194
Epoch: 960  Train Loss: 476.3735163110087  Validation Loss: 1604.7452094364876
Epoch: 970  Train Loss: 344.9955501905751  Validation Loss: 1517.7027735773797
Epoch: 980  Train Loss: 464.9664558102833  Validation Loss: 1927.8618293814982
Epoch: 990  Train Loss: 375.14682809087617  Validation Loss: 2277.1267155397068
torch.Size([8100])
torch.Size([8100])
100
100
Average Test Loss (MSE) tensor(1249.7954, device='cuda:0', grad_fn=<DivBackward0>)