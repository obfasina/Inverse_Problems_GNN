Time to play:
Loading lists of data
graph data Data(x=[81, 1], edge_index=[2, 324], y=[81], pos=[81, 2])
Epoch: 10  Train Loss: 83777.28399508526  Validation Loss: 82042.48521602663
Epoch: 20  Train Loss: 82621.29971312943  Validation Loss: 79762.80021899915
Epoch: 30  Train Loss: 80024.01978520826  Validation Loss: 76180.26702745711
Epoch: 40  Train Loss: 75294.81694688031  Validation Loss: 68311.0020154629
Epoch: 50  Train Loss: 68117.5800539576  Validation Loss: 58943.17339627253
Epoch: 60  Train Loss: 58917.02762117072  Validation Loss: 50043.32765955064
Epoch: 70  Train Loss: 47815.95727842461  Validation Loss: 44844.97333998739
Epoch: 80  Train Loss: 36514.229739132534  Validation Loss: 44005.74861825536
Epoch: 90  Train Loss: 26761.268349229533  Validation Loss: 46300.933934699446
torch.Size([8100])
torch.Size([8100])
100
100
[[ 41.90768   137.       ]
 [240.51208   386.       ]
 [ 93.808136  207.       ]
 [179.42044   313.       ]
 [ 60.591133  163.       ]
 [329.8644    491.       ]
 [288.994     443.       ]
 [297.50653   453.       ]
 [262.61746   412.       ]
 [215.05577   356.       ]
 [266.01984   416.       ]
 [315.3859    474.       ]
 [  3.3146513  32.       ]
 [110.65426   228.       ]
 [101.02561   216.       ]
 [330.71622   492.       ]
 [309.42545   467.       ]
 [163.95769   294.       ]
 [106.64113   223.       ]
 [ 74.590294  182.       ]
 [ 10.077708   83.       ]
 [ 66.44625   171.       ]
 [ 26.752073  113.       ]
 [  3.3176548  59.       ]
 [  3.3146513  40.       ]
 [ 23.090822  107.       ]
 [  3.3146513  12.       ]
 [247.31271   394.       ]
 [  3.3146513  38.       ]
 [ 96.21287   210.       ]
 [  7.834952   78.       ]
 [  3.3146513  43.       ]
 [ 52.579422  152.       ]
 [ 33.503983  124.       ]
 [168.83432   300.       ]
 [243.06218   389.       ]
 [187.58717   323.       ]
 [170.46126   302.       ]
 [184.3194    319.       ]
 [  3.3146513  23.       ]
 [ 57.67302   159.       ]
 [ 82.107666  192.       ]
 [215.90218   357.       ]
 [ 35.359818  127.       ]
 [  3.3146513   2.       ]
 [162.33264   292.       ]
 [  3.3146513   0.       ]
 [ 23.700596  108.       ]
 [298.35785   454.       ]
 [318.79205   478.       ]
 [148.54321   275.       ]
 [ 40.52464   135.       ]
 [263.46802   413.       ]
 [274.52655   426.       ]
 [  3.3146513   6.       ]
 [ 73.84288   181.       ]
 [ 64.24705   168.       ]
 [ 82.86488   193.       ]
 [254.11403   402.       ]
 [122.7082    243.       ]
 [109.04837   226.       ]
 [161.52019   291.       ]
 [ 44.712063  141.       ]
 [  5.6462     73.       ]
 [ 25.531202  111.       ]
 [308.574     466.       ]
 [  6.5112267  75.       ]
 [312.8314    471.       ]
 [188.40488   324.       ]
 [ 24.920937  110.       ]
 [  3.3146513  44.       ]
 [  3.3146513  18.       ]
 [328.16083   489.       ]
 [129.14166   251.       ]
 [250.7133    398.       ]
 [203.26138   342.       ]
 [260.9165    410.       ]
 [112.26145   230.       ]
 [  6.9517794  76.       ]
 [197.43962   335.       ]
 [195.78926   333.       ]
 [  3.3146513  39.       ]
 [277.07898   429.       ]
 [204.93616   344.       ]
 [124.315475  245.       ]
 [107.44355   224.       ]
 [ 92.209114  205.       ]
 [264.31857   414.       ]
 [  3.3146513  14.       ]
 [ 54.032593  154.       ]
 [168.02124   299.       ]
 [ 75.33843   183.       ]
 [ 79.843704  189.       ]
 [ 68.6493    174.       ]
 [266.87045   417.       ]
 [230.31712   374.       ]
 [  3.7312312  66.       ]
 [  3.3146513   3.       ]
 [316.23743   475.       ]
 [ 46.831997  144.       ]]
Average Test Loss (MSE) tensor(44859.3789, device='cuda:0', grad_fn=<DivBackward0>)