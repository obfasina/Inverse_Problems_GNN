Time to play:
Loading lists of data
graph data Data(x=[81, 1], edge_index=[2, 324], y=[81], pos=[81, 2])
Epoch: 10  Train Loss: 83583.51043710388  Validation Loss: 81392.4364942025
Epoch: 20  Train Loss: 82322.18366482008  Validation Loss: 78890.23730037065
Epoch: 30  Train Loss: 79410.86963047317  Validation Loss: 74673.07133607182
Epoch: 40  Train Loss: 74493.1917971641  Validation Loss: 65868.59545384481
Epoch: 50  Train Loss: 67143.87294338705  Validation Loss: 53858.95696858119
Epoch: 60  Train Loss: 57786.9783132392  Validation Loss: 47851.79489991837
Epoch: 70  Train Loss: 47131.73858272426  Validation Loss: 43987.179750369934
Epoch: 80  Train Loss: 37340.75110250062  Validation Loss: 44985.48640399013
Epoch: 90  Train Loss: 29290.234251196012  Validation Loss: 47125.35510524902
Epoch: 100  Train Loss: 22441.725693880115  Validation Loss: 44737.456881608436
Epoch: 110  Train Loss: 15578.582338004815  Validation Loss: 36653.919030906334
Epoch: 120  Train Loss: 10893.932473038794  Validation Loss: 30808.731129594395
Epoch: 130  Train Loss: 8087.018959843379  Validation Loss: 17988.150486020888
Epoch: 140  Train Loss: 6479.398631032264  Validation Loss: 11835.207415141635
Epoch: 150  Train Loss: 7656.612657953966  Validation Loss: 21879.493378292387
Epoch: 160  Train Loss: 6481.806340825085  Validation Loss: 19157.50190441565
Epoch: 170  Train Loss: 4905.911945558633  Validation Loss: 15097.768391517413
Epoch: 180  Train Loss: 4799.767658742603  Validation Loss: 11038.725383516803
Epoch: 190  Train Loss: 4612.148314602196  Validation Loss: 12852.863965572484
Epoch: 200  Train Loss: 4502.671163693397  Validation Loss: 19977.62120328293
Epoch: 210  Train Loss: 4524.03371204571  Validation Loss: 20549.422754025334
Epoch: 220  Train Loss: 4326.991969796534  Validation Loss: 12518.074553821732
Epoch: 230  Train Loss: 4961.395913307873  Validation Loss: 18555.735964990294
Epoch: 240  Train Loss: 3990.275110001987  Validation Loss: 8281.541934996681
Epoch: 250  Train Loss: 3930.102742843605  Validation Loss: 13495.468398680248
Epoch: 260  Train Loss: 3675.1199461408287  Validation Loss: 14429.689462469853
Epoch: 270  Train Loss: 4126.088520563198  Validation Loss: 7513.760256699322
Epoch: 280  Train Loss: 3478.031151503174  Validation Loss: 7817.963717703866
Epoch: 290  Train Loss: 3262.3962846434747  Validation Loss: 7160.52172395578
Epoch: 300  Train Loss: 3088.4047196798747  Validation Loss: 6541.769160728115
Epoch: 310  Train Loss: 3733.3190231478397  Validation Loss: 9290.970702275321
Epoch: 320  Train Loss: 3221.8774121667243  Validation Loss: 8183.7193834440695
Epoch: 330  Train Loss: 2957.362384717304  Validation Loss: 5905.713634293013
Epoch: 340  Train Loss: 3039.4655363791876  Validation Loss: 5795.1378941441635
Epoch: 350  Train Loss: 2946.8249928328883  Validation Loss: 5079.671194293427
Epoch: 360  Train Loss: 2675.4650701201213  Validation Loss: 5127.766050483792
Epoch: 370  Train Loss: 2730.397503627018  Validation Loss: 4713.776090454154
Epoch: 380  Train Loss: 2499.6132708003374  Validation Loss: 5999.524263811233
Epoch: 390  Train Loss: 2225.8697458595348  Validation Loss: 4597.676678105844
Epoch: 400  Train Loss: 2405.219712337405  Validation Loss: 5355.224476267415
Epoch: 410  Train Loss: 2043.283175374897  Validation Loss: 4251.913376345237
Epoch: 420  Train Loss: 2123.838103466993  Validation Loss: 4178.401044066002
Epoch: 430  Train Loss: 1868.117977614419  Validation Loss: 4013.2387822487217
Epoch: 440  Train Loss: 1783.290005134114  Validation Loss: 3611.854255159516
Epoch: 450  Train Loss: 1902.86040564863  Validation Loss: 3739.5818286369663
Epoch: 460  Train Loss: 2066.7946253980103  Validation Loss: 3547.2636198832074
Epoch: 470  Train Loss: 1632.88989758074  Validation Loss: 3522.4389874468975
Epoch: 480  Train Loss: 1444.0974138326073  Validation Loss: 3114.7122862866595
Epoch: 490  Train Loss: 1591.3428703218433  Validation Loss: 2935.989809580008
Epoch: 500  Train Loss: 1704.2963088670167  Validation Loss: 2988.599445485664
Epoch: 510  Train Loss: 3498.982210562857  Validation Loss: 5017.264384147838
Epoch: 520  Train Loss: 1874.7213816740314  Validation Loss: 3511.833551254057
Epoch: 530  Train Loss: 1718.5301750151427  Validation Loss: 3301.985274317684
Epoch: 540  Train Loss: 1536.0980709389607  Validation Loss: 2545.8236981920895
Epoch: 550  Train Loss: 1385.609670100249  Validation Loss: 3137.9463807500033
Epoch: 560  Train Loss: 1398.6314120223478  Validation Loss: 2676.9608742089304
Epoch: 570  Train Loss: 1554.9316829553018  Validation Loss: 1838.4051342218524
Epoch: 580  Train Loss: 1030.791115319246  Validation Loss: 2095.3316213135536
Epoch: 590  Train Loss: 1009.3965012267345  Validation Loss: 2608.285619714764
Epoch: 600  Train Loss: 1061.7403289577462  Validation Loss: 1913.050145410092
Epoch: 610  Train Loss: 1209.05092772598  Validation Loss: 4747.692463815146
Epoch: 620  Train Loss: 1120.1348418290547  Validation Loss: 2649.055703160417
Epoch: 630  Train Loss: 1009.6848591098114  Validation Loss: 1843.6474457409572
Epoch: 640  Train Loss: 1133.5476314393636  Validation Loss: 2606.486862577214
Epoch: 650  Train Loss: 826.0411149923651  Validation Loss: 2376.136492442315
Epoch: 660  Train Loss: 875.8677063110805  Validation Loss: 1934.4614089451295
Epoch: 670  Train Loss: 1169.8273462691764  Validation Loss: 3381.985982813153
Epoch: 680  Train Loss: 779.6015287353129  Validation Loss: 2085.806353774142
Epoch: 690  Train Loss: 911.1585451236639  Validation Loss: 1835.1455753743194
Epoch: 700  Train Loss: 721.4048261539225  Validation Loss: 1693.4126753842606
Epoch: 710  Train Loss: 733.1807088834468  Validation Loss: 2620.736156548118
Epoch: 720  Train Loss: 970.1208297055605  Validation Loss: 2024.7403786634204
Epoch: 730  Train Loss: 1176.5433453601338  Validation Loss: 3071.196733452938
Epoch: 740  Train Loss: 1113.2408446988502  Validation Loss: 3326.433731504601
Epoch: 750  Train Loss: 1311.0146972086511  Validation Loss: 2455.5035890377517
Epoch: 760  Train Loss: 941.2614555164282  Validation Loss: 3255.170542716916
Epoch: 770  Train Loss: 1086.120622806315  Validation Loss: 2092.2380095826843
Epoch: 780  Train Loss: 858.5878195788267  Validation Loss: 2556.01498818696
Epoch: 790  Train Loss: 857.9470336439794  Validation Loss: 1775.3228163287506
Epoch: 800  Train Loss: 928.8139019470142  Validation Loss: 2122.6337158294077
Epoch: 810  Train Loss: 783.6658943897687  Validation Loss: 1777.4422799835345
Epoch: 820  Train Loss: 1069.9720112319249  Validation Loss: 2115.557504456409
Epoch: 830  Train Loss: 859.9836749749016  Validation Loss: 1765.457621665878
Epoch: 840  Train Loss: 591.3726512286099  Validation Loss: 2725.142564968118
Epoch: 850  Train Loss: 738.5414211966271  Validation Loss: 2428.866669802576
Epoch: 860  Train Loss: 682.330424728537  Validation Loss: 1874.026459813226
Epoch: 870  Train Loss: 580.5816757218803  Validation Loss: 1676.3910008505777
Epoch: 880  Train Loss: 895.2537137768554  Validation Loss: 1820.7959118724932
Epoch: 890  Train Loss: 819.2147482713272  Validation Loss: 2404.534008159767
Epoch: 900  Train Loss: 506.42461570515616  Validation Loss: 1671.027240141971
Epoch: 910  Train Loss: 987.8374955419189  Validation Loss: 1921.283470485867
Epoch: 920  Train Loss: 512.2397362351285  Validation Loss: 1633.9833841323682
Epoch: 930  Train Loss: 623.2596470532685  Validation Loss: 2506.571551905441
Epoch: 940  Train Loss: 810.805447907208  Validation Loss: 1911.2136585297505
Epoch: 950  Train Loss: 542.843109084397  Validation Loss: 3212.904721196964
Epoch: 960  Train Loss: 688.0199082881863  Validation Loss: 2174.70528630524
Epoch: 970  Train Loss: 693.2789687696637  Validation Loss: 2043.804771884765
Epoch: 980  Train Loss: 593.5700776543487  Validation Loss: 2595.3153470040015
Epoch: 990  Train Loss: 620.8712337955453  Validation Loss: 1956.8075498698975
torch.Size([8100])
torch.Size([8100])
100
100
Average Test Loss (MSE) tensor(1574.0061, device='cuda:0', grad_fn=<DivBackward0>)