Time to play:
Loading lists of data
graph data Data(x=[81, 1], edge_index=[2, 324], y=[81], pos=[81, 2])
Epoch: 10  Train Loss: 83648.087292406  Validation Loss: 81571.70115194304
Epoch: 20  Train Loss: 82382.19182194585  Validation Loss: 79020.81849737203
Epoch: 30  Train Loss: 79724.29893226169  Validation Loss: 74598.4676906168
Epoch: 40  Train Loss: 74957.42563013792  Validation Loss: 67345.02648552472
Epoch: 50  Train Loss: 67843.76113573198  Validation Loss: 58088.3809528393
Epoch: 60  Train Loss: 58355.97240235881  Validation Loss: 50270.951589408185
Epoch: 70  Train Loss: 48159.717254273426  Validation Loss: 44704.54907944364
Epoch: 80  Train Loss: 37345.681522455285  Validation Loss: 44190.42256476134
Epoch: 90  Train Loss: 27068.222920863394  Validation Loss: 46481.70986442321
Epoch: 100  Train Loss: 18872.468631240354  Validation Loss: 47610.863892083275
Epoch: 110  Train Loss: 12877.073881426024  Validation Loss: 45500.67371253067
Epoch: 120  Train Loss: 6180.875772681553  Validation Loss: 39724.87838840939
Epoch: 130  Train Loss: 2734.7452935050455  Validation Loss: 34299.040603751586
Epoch: 140  Train Loss: 1882.1455580824613  Validation Loss: 21629.05071934202
Epoch: 150  Train Loss: 4135.451731261192  Validation Loss: 23410.9424574102
Epoch: 160  Train Loss: 2361.31919579084  Validation Loss: 22628.654215789593
Epoch: 170  Train Loss: 2250.4966014395136  Validation Loss: 20696.02641731462
Epoch: 180  Train Loss: 2451.6249905529094  Validation Loss: 27266.82688495319
Epoch: 190  Train Loss: 2306.953795528836  Validation Loss: 16620.32574584301
Epoch: 200  Train Loss: 2170.3377934722716  Validation Loss: 17004.714137090352
Epoch: 210  Train Loss: 2568.1116493932204  Validation Loss: 18469.021339151786
Epoch: 220  Train Loss: 1598.9554633264331  Validation Loss: 16442.136523300753
Epoch: 230  Train Loss: 3581.979977439534  Validation Loss: 14787.033204977208
Epoch: 240  Train Loss: 1788.2582942156444  Validation Loss: 13481.653857765894
Epoch: 250  Train Loss: 1443.441539232599  Validation Loss: 12051.143178351294
Epoch: 260  Train Loss: 2191.372406978331  Validation Loss: 9785.814448603047
Epoch: 270  Train Loss: 1343.1399831189726  Validation Loss: 10568.709086082968
Epoch: 280  Train Loss: 1505.9661344328476  Validation Loss: 7793.527259278209
Epoch: 290  Train Loss: 1340.9403605263287  Validation Loss: 11133.940781970496
Epoch: 300  Train Loss: 1027.9049942105983  Validation Loss: 5931.399564161758
Epoch: 310  Train Loss: 1064.8753426695641  Validation Loss: 6403.399725350966
Epoch: 320  Train Loss: 1125.844422598716  Validation Loss: 4802.179519991737
Epoch: 330  Train Loss: 1433.212417364738  Validation Loss: 4877.039044982259
Epoch: 340  Train Loss: 918.3491764945284  Validation Loss: 5080.260292602655
Epoch: 350  Train Loss: 828.7099417692198  Validation Loss: 4676.685833248916
Epoch: 360  Train Loss: 840.0618750037023  Validation Loss: 4256.49217038758
Epoch: 370  Train Loss: 743.2065575684122  Validation Loss: 3906.194823255746
Epoch: 380  Train Loss: 696.1606924848044  Validation Loss: 4034.553249410407
Epoch: 390  Train Loss: 822.9892039624623  Validation Loss: 6013.545453304209
Epoch: 400  Train Loss: 626.1561232253439  Validation Loss: 4604.513766482122
Epoch: 410  Train Loss: 618.0921420099745  Validation Loss: 4418.514856178198
Epoch: 420  Train Loss: 709.1727961745347  Validation Loss: 3286.2550632212933
Epoch: 430  Train Loss: 847.133993077578  Validation Loss: 3541.1397542656573
Epoch: 440  Train Loss: 525.884994067298  Validation Loss: 3543.207784407144
Epoch: 450  Train Loss: 788.5216650049538  Validation Loss: 4366.280628983764
Epoch: 460  Train Loss: 467.73861626222333  Validation Loss: 2813.151963633704
Epoch: 470  Train Loss: 586.0027301906881  Validation Loss: 4793.296498469949
Epoch: 480  Train Loss: 1152.8787623345618  Validation Loss: 4425.429410574138
Epoch: 490  Train Loss: 716.6867398819422  Validation Loss: 2785.075807734702
Epoch: 500  Train Loss: 519.9162799163906  Validation Loss: 2861.779121954869
Epoch: 510  Train Loss: 551.8430353609216  Validation Loss: 3453.5167498348733
Epoch: 520  Train Loss: 503.0187403316886  Validation Loss: 2442.456298921828
Epoch: 530  Train Loss: 437.87032075191115  Validation Loss: 2448.3968277421363
Epoch: 540  Train Loss: 462.3466943265424  Validation Loss: 2792.9109332914177
Epoch: 550  Train Loss: 619.7642298990514  Validation Loss: 4591.369076768951
Epoch: 560  Train Loss: 535.7895839367159  Validation Loss: 5275.221087827567
Epoch: 570  Train Loss: 707.1374954646449  Validation Loss: 2180.9005371086787
Epoch: 580  Train Loss: 611.9200926733268  Validation Loss: 2429.198921964949
Epoch: 590  Train Loss: 594.5168444148807  Validation Loss: 3449.484852155023
Epoch: 600  Train Loss: 744.6774354864541  Validation Loss: 2675.8826129990825
Epoch: 610  Train Loss: 537.3152354421253  Validation Loss: 3554.1531958181877
Epoch: 620  Train Loss: 824.3396024572017  Validation Loss: 2772.532619314365
Epoch: 630  Train Loss: 638.720867098987  Validation Loss: 3937.5023019835244
Epoch: 640  Train Loss: 545.5509039023384  Validation Loss: 2480.8828263000096
Epoch: 650  Train Loss: 564.1185689703781  Validation Loss: 2533.2201725078467
Epoch: 660  Train Loss: 525.0902759739325  Validation Loss: 1889.8092334355476
Epoch: 670  Train Loss: 502.49600296021805  Validation Loss: 4028.231544589553
Epoch: 680  Train Loss: 504.0898349725563  Validation Loss: 1952.5104050920463
Epoch: 690  Train Loss: 475.86732823359915  Validation Loss: 2132.535539895337
Epoch: 700  Train Loss: 387.96489967921525  Validation Loss: 1668.0812735840802
Epoch: 710  Train Loss: 522.9141231390654  Validation Loss: 1814.6222308261076
Epoch: 720  Train Loss: 385.57925041976114  Validation Loss: 1620.1367247181865
Epoch: 730  Train Loss: 516.2691488296122  Validation Loss: 3244.4114506076103
Epoch: 740  Train Loss: 544.6726360162183  Validation Loss: 1929.0080696989435
Epoch: 750  Train Loss: 622.9023731824775  Validation Loss: 2079.590705688773
Epoch: 760  Train Loss: 520.5291016472542  Validation Loss: 3676.723993519422
Epoch: 770  Train Loss: 558.992725927179  Validation Loss: 3943.2397935277177
Epoch: 780  Train Loss: 360.4654944305573  Validation Loss: 2230.5066040750876
Epoch: 790  Train Loss: 679.7931714972574  Validation Loss: 3943.709493516833
Epoch: 800  Train Loss: 403.79528389854244  Validation Loss: 1465.4637986720547
Epoch: 810  Train Loss: 710.7611990207424  Validation Loss: 2129.690815921136
Epoch: 820  Train Loss: 384.34701976083346  Validation Loss: 1741.741725991923
Epoch: 830  Train Loss: 446.0020214378224  Validation Loss: 1989.9690066387118
Epoch: 840  Train Loss: 456.4850536704668  Validation Loss: 2613.1228204027816
Epoch: 850  Train Loss: 676.3917634935119  Validation Loss: 2746.5979955201524
Epoch: 860  Train Loss: 453.09985121482185  Validation Loss: 3841.604733379739
Epoch: 870  Train Loss: 431.8506130390876  Validation Loss: 2313.1939030976077
Epoch: 880  Train Loss: 392.21126020266956  Validation Loss: 2169.8521827774593
Epoch: 890  Train Loss: 535.3194179390215  Validation Loss: 1487.6177407529854
Epoch: 900  Train Loss: 518.2494040492446  Validation Loss: 4441.951662732054
Epoch: 910  Train Loss: 547.4905308610942  Validation Loss: 1944.12918259263
Epoch: 920  Train Loss: 439.21167082680876  Validation Loss: 1201.3275281253739
Epoch: 930  Train Loss: 671.0071982133567  Validation Loss: 2581.8903511170042
Epoch: 940  Train Loss: 568.6903926770934  Validation Loss: 1223.735080562227
Epoch: 950  Train Loss: 523.0039978430185  Validation Loss: 4729.168151338636
Epoch: 960  Train Loss: 414.85126209912937  Validation Loss: 2683.385512701601
Epoch: 970  Train Loss: 395.8738116079317  Validation Loss: 1475.5870957324378
Epoch: 980  Train Loss: 337.0936713607371  Validation Loss: 1362.5893339780303
Epoch: 990  Train Loss: 531.4183200589973  Validation Loss: 1351.5611849806473
torch.Size([8100])
torch.Size([8100])
100
100
Average Test Loss (MSE) tensor(1608.2604, device='cuda:0', grad_fn=<DivBackward0>)